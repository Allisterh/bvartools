---
title: "Bayesian Variable Selection"
author: "Franz X. Mohr"
date: "2019-02-15"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bayesian Variable Selection}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

A general drawback of vector autoregressive (VAR) models is that the number of estimated coefficients increases disproportionately with the number of lags. Therefore, fewer information per parameter is available to find its "true" value. In the Bayesian VAR literature one approach to mitigate this *curse of dimensionality* is so-called *stochastic search variable selection* (SSVS) as proposed by George et al. (2008). The basic idea of SSVS is to assign commonly used prior variance values to parameters, which should be included in a model, and prior variances close to zero to irrelevant parameters. By that, relevant parameters are estimated in the usual way and posterior draws of irrelevant variables are close to zero so that they have no significant effect on forecasts and impulse responses. The only remaining challenge is to find out, which parameter is relevant and which is not.

In contrast to stochastic search variable selection (SSVS) as proposed by George et al. (2008), BVS is more flexible by allowing for time varying parameters and stochastic volatility.

This vignette presents code for the estimation of a Bayesian vector autoregressive (BVAR) model, where stochastic search variable selection is used to select the relevant variables. For this illustration the dataset E1 from Lütkepohl (2007) is used, which contains data on West German fixed investment, disposable income and consumption expenditures in billions of DM from 1960Q1 to 1982Q4. Following a related example in Lütkepohl (2007, Section 5.2.10), only the first 71 observations of a VAR(4) model are used. The `bvartools` packages can be used to load the data and generate the data matrices:

```{r data, fig.align='center', fig.height=5, fig.width=4.5}
# devtools::install_github("franzmohr/bvartools")
library(bvartools)

# Load and transform data
data("e1")
e1 <- diff(log(e1))

# Generate VAR
data <- gen_var(e1, p = 4, deterministic = "const")

# Get data matrices
y <- data$Y[, 1:71]
x <- data$Z[, 1:71]
```

## Estimation

The `bvartools` package can be used to include SSVS in a Gibbs sampler. In this example the Gibbs sampler produces 50,000 posterior draws, where the first 10,000 are dropped. Prior variances of the parameters are set by following the semiautomatic approach in George et al. (2008). Hence, the prior variance of the $i$th parameter is set to $10 \hat{\sigma}_i$ when a variable should be included in the model an to $0.1 \hat{\sigma}_i$ if it should be excluded. $\hat{\sigma}_i$ is the standard error associated with the unconstrained least squares estimate of parameter $i$. The prior inclusion probability of all estimated parameters is set to 0.5.

```{r}
t <- ncol(y) # Number of observations
k <- nrow(y) # Number of endogenous variables
m <- k * nrow(x) # Number of estimated coefficients

z <- kronecker(t(x), diag(1, k))

# Set priors
a_mu_prior <- matrix(0, m) # Vector of prior parameter means
a_v_i_prior <- diag(1 / 9, m) # Inverse of the prior covariance matrix

prob_prior <- matrix(0.5, m)
```

For the error variance-covariance matrix a non-informative prior is used.

```{r}
u_sigma_df_prior <- 0 # Prior degrees of freedom
u_sigma_scale_prior <- diag(0, k) # Prior covariance matrix
u_sigma_df_post <- t + u_sigma_df_prior # Posterior degrees of freedom

# Initial values
a <- matrix(0, m)
Lambda <- diag(1, m)

# Data containers for posterior draws
iter <- 50000 # Number of iterations of the Gibbs sampler
burnin <- 10000 # Number of burn-in draws
store <- iter - burnin
draws_a <- matrix(NA, m, store)
draws_lambda <- matrix(NA, m, store)
draws_sigma <- matrix(NA, k^2, store)
```

Add a block to the Gibbs sampler. Deterministic terms are exlcuded from SSVS here. 
Deterministic terms are excluded from SSVS. Therefore, only the first 36 variables considered.

```{r}
# Reset random number generator for reproducibility
set.seed(1234567)

# Start Gibbs sampler
for (draw in 1:iter) {
  # Draw variance-covariance matrix
  u <- y - matrix(a, k) %*% x # Obtain residuals
  u_sigma_scale_post <- solve(u_sigma_scale_prior + tcrossprod(u))
  u_sigma_i <- matrix(rWishart(1, u_sigma_df_post, u_sigma_scale_post)[,, 1], k)
  u_sigma <- solve(u_sigma_i) # Invert Sigma_i to obtain Sigma
  
  # Draw conditional mean parameters
  z_bvs <- z %*% Lambda
  a <- post_normal_sur(y, z_bvs, u_sigma_i, a_mu_prior, a_v_i_prior)
  
  # BVS block
  Lambda <- bvs(y, z, a, Lambda, u_sigma_i, prob_prior, include = 1:36)
  a <- Lambda %*% a
  
  # Store draws
  if (draw > burnin) {
    draws_a[, draw - burnin] <- a
    draws_lambda[, draw - burnin] <- diag(Lambda)
    draws_sigma[, draw - burnin] <- u_sigma
  }
}
```

After the Gibbs sampler has finished, point estimates can be obtained as the mean of posterior draws:

```{r}
lambda <- rowMeans(draws_lambda) # Obtain means for every row
lambda <- matrix(lambda, k) # Transform mean vector into a matrix
lambda <- round(lambda, 2) # Round values
dimnames(lambda) <- list(dimnames(y)[[1]], dimnames(x)[[1]]) # Rename matrix dimensions

lambda # Print
```

Given these posterior inclusion probabilites, the researcher could proceed in the usual way and obtain forecasts or impulse responses based on the output of the Gibbs sampler. A different approach would be to repeat the Gibbs sampler step, but only include the relevant variables. The merits of this approach might become clearer when looking at a histogram of the first parameter:

```{r, fig.height=3.5, fig.width=4.5}
hist(draws_a[6,], main = "Histogram", xlab = "6th variable")
```

A non-negligible mass, i.e. 1 - 0.67, of the parameter is concentrated around 0.

```{r}
# Select variables that should be included
include_var <- c(lambda >= .5)

# Data containers for posterior draws
draws_a <- matrix(NA, m, store)
draws_sigma <- matrix(NA, k^2, store)

Lambda <- diag(0, m)
diag(Lambda)[include_var] <- 1
z_restricted <- z %*% Lambda

# Start Gibbs sample0r
for (draw in 1:iter) {
  # Draw conditional mean parameters
  a <- post_normal_sur(y, z_restricted, u_sigma_i, a_mu_prior, a_v_i_prior)
  a <- Lambda %*% a
  
  # Draw variance-covariance matrix
  u <- y - matrix(a, k) %*% x # Obtain residuals
  u_sigma_scale_post <- solve(u_sigma_scale_prior + tcrossprod(u))
  u_sigma_i <- matrix(rWishart(1, u_sigma_df_post, u_sigma_scale_post)[,, 1], k)
  u_sigma <- solve(u_sigma_i) # Invert Sigma_i to obtain Sigma
  
  # Store draws
  if (draw > burnin) {
    draws_a[, draw - burnin] <- a
    draws_sigma[, draw - burnin] <- u_sigma
  }
}
```


```{r}
A <- rowMeans(draws_a) # Obtain means for every row
A <- matrix(A, k) # Transform mean vector into a matrix
A <- round(A, 3) # Round values
dimnames(A) <- list(dimnames(y)[[1]], dimnames(x)[[1]]) # Rename matrix dimensions

A # Print
```

The means of the coefficient draws are very close to the results of the frequentist estimatior, which would be expected with non-informative priors.

## `bvar` objects

The `bvar` function can be used to collect relevant output of the Gibbs sampler into a standardised object, which can be used by further functions such as `predict` to obtain forecasts or `irf` for impulse respons analysis.

```{r bvar-object}
bvar_est <- bvar(y = y, x = x, A = draws_a[1:36,],
                 C = draws_a[37:39, ], Sigma = draws_sigma)
```

## Forecasts

Forecasts with credible bands can be obtained with the function `predict`. If the model contains deterministic terms, new values can be provided in the argument `new_D`. If no values are provided, the function sets them to zero. The number of rows of `new_D` must be the same as the argument `n.ahead`.

```{r forecasts, fig.width=5.5, fig.height=5.5}
bvar_pred <- predict(bvar_est, n.ahead = 10, new_D = rep(1, 10))

plot(bvar_pred)
```

## Impulse response analysis

```{r oir, fig.width=5.5, fig.height=4.5}
OIR <- irf(bvar_est, impulse = "income", response = "cons", n.ahead = 8, type = "oir")

plot(OIR, main = "Orthogonalised Impulse Response", xlab = "Period", ylab = "Response")
```

## References

George, E. I., Sun, D., & Ni, S. (2008). Bayesian stochastic search for VAR model restrictions. *Journal of Econometrics, 142*(1), 553-580. <https://doi.org/10.1016/j.jeconom.2007.08.017>

Lütkepohl, H. (2007). *New introduction to multiple time series analyis*. Berlin: Springer.